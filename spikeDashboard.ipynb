{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48da973b",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ed21b-a28d-4bf9-98c1-b3539408f47e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys, re\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import time\n",
    "\n",
    "# Import custom utility functions\n",
    "import glycan_bionames\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Define custom functions\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "def restrict_RBD_window(df,nm):\n",
    "    '''Function to drop features of dataframe that correspond to glycans which are outside a given RBD neighborhood (in nm)'''\n",
    "    #Get list of glycans\n",
    "    glycans = list(np.unique([x.replace('RBD__2__','') for x in df.keys().to_list() if 'RBD__2__GLY' in x]))\n",
    "    \n",
    "    for g in glycans:\n",
    "        if df['RBD__2__' + g].mean() > nm:\n",
    "            for f in ['RBD__2__'+g,g+':ROF',g+':RMSD',g+'_x',g+'_y',g+'_z']:\n",
    "                if f in df.keys().to_list():\n",
    "                    df.drop([f],axis=1,inplace=True)    \n",
    "    return df\n",
    "\n",
    "def overlapping_hist(open_df,closed_df,feat):\n",
    "    '''Plot overlapping histograms for a given feature of all datasets'''\n",
    "    open_df[feat].hist(bins=50)\n",
    "    closed_df[feat].hist(bins=50)\n",
    "    mutant_df[feat].hist(bins=50)\n",
    "    plt.legend(['Open','Closed','Mutant (open)'])\n",
    "    plt.title(feat)\n",
    "    if 'RBD__2__' in feat:\n",
    "        plt.xlabel('nm')\n",
    "        \n",
    "def drop_feats(df,flag):\n",
    "    '''Drops all features in df containing flag'''\n",
    "    for f in df.keys().to_list():\n",
    "        if flag in f:\n",
    "            df.drop(f,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def read_n_filter_dfs(fname,num_reps,RBD_wind,val_reps_open,val_reps_closed,label_val,dfs_train=None,dfs_val=None):\n",
    "    '''Reads data and filters columns, then places in either train or validation dataframe list'''\n",
    "    if dfs_train is None:\n",
    "        dfs_train = []\n",
    "    if dfs_val is None:\n",
    "        dfs_val = []\n",
    "        \n",
    "    for i in range(1,num_reps+1):\n",
    "        df = pd.read_csv(fname+'.csv').assign(label=label_val).iloc[:,1:]\n",
    "        # Only use glycans within certain range of the RBD\n",
    "        df = restrict_RBD_window(df,RBD_wind)\n",
    "        # Drop _x, _y, and _z features\n",
    "        df = drop_feats(df,'_x')\n",
    "        df = drop_feats(df,'_y')\n",
    "        #df = drop_feats(df,'RBD__2__')\n",
    "        df = drop_feats(df,'_z')\n",
    "        \n",
    "        # Withold some replicants for use in a separate validation set\n",
    "        if (label_val==1) & (i in val_reps_open):\n",
    "            dfs_val.append(df)\n",
    "        elif (label_val==0) & (i in val_reps_closed):\n",
    "            dfs_val.append(df)\n",
    "        else:\n",
    "            dfs_train.append(df)\n",
    "            \n",
    "    return dfs_train, dfs_val\n",
    "\n",
    "def remove_corr_feats(full_df,corr_thresh= 0.65):\n",
    "    '''Remove highly correlated features'''\n",
    "    corr_matrix = full_df.corr()\n",
    "    final_features = corr_matrix['RBD_CA0:RMSD'][(corr_matrix['RBD_CA0:RMSD'] < corr_thresh) & (corr_matrix['RBD_CA0:RMSD'] > -corr_thresh)].reset_index().loc[:,'index'].to_list()\n",
    "    if 'label' not in final_features:\n",
    "        final_features.append('label')\n",
    "    clf_df = full_df.loc[:,final_features]\n",
    "    return clf_df\n",
    "\n",
    "def prep_ML_data(clf_df,ts,rs,labelnames):\n",
    "    '''Prepare data for use in training machine learning algorithm'''\n",
    "    # Split training and testing data\n",
    "    train_set, test_set = train_test_split(clf_df,test_size=ts, random_state=rs,stratify=labelnames)\n",
    "    print(f'Train set : {train_set.shape}, Test set : {test_set.shape}')\n",
    "\n",
    "    # Split data and labels\n",
    "    train_X = train_set.drop(\"label\", axis=1) # drop labels for training set\n",
    "    train_labels = train_set[\"label\"].copy()\n",
    "    test_X = test_set.drop(\"label\", axis=1) # drop labels for training set\n",
    "    test_labels = test_set[\"label\"].copy()\n",
    "\n",
    "    return train_X, test_X, train_labels, test_labels\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3fecd",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d49f8d",
   "metadata": {},
   "source": [
    "### Load all replicants as one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset\n",
    "fname = '/net/jam-amaro-shared/dse_project/Spike_Dataset/TRAJECTORIES_spike_open_prot_glyc_amarolab/results/FinalExtractedFeature_open.csv'\n",
    "open_df = pd.read_csv(fname).assign(label = 1).iloc[:,1:]\n",
    "\n",
    "# Closed dataset\n",
    "fname = '/net/jam-amaro-shared/dse_project/Spike_Dataset/TRAJECTORIES_spike_closed_prot_glyc_amarolab/results/FinalExtractedFeature_closed.csv'\n",
    "closed_df = pd.read_csv(fname).assign(label = 0).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77d4d8-0379-4c83-a48b-f1f8c62b4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutant dataset\n",
    "fname = '/net/jam-amaro-shared/dse_project/Spike_Dataset/TRAJECTORIES_spike_mutant_prot_glyc_amarolab/results/FinalExtractedFeature_mutant.csv'\n",
    "mutant_df = pd.read_csv(fname).assign(label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d50fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening dataset\n",
    "fname = '/net/jam-amaro-shared/dse_project/Spike_Dataset/TRAJECTORIES_continuous_spike_opening_WE_chong_and_amarolab/results/FinalExtractedFeature.csv'\n",
    "opening_df = pd.read_csv(fname)\n",
    "xidx = 1500\n",
    "opening_df.loc[:xidx,'label'] = 0\n",
    "opening_df.loc[xidx:,'label'] = 1\n",
    "fig = px.line(opening_df,y = ['RBD__2__CH_CA0','RBD__2__backbone0'],title='Labeling Closed and Open')\n",
    "fig.add_vline(x=xidx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82aecd",
   "metadata": {},
   "source": [
    "# Filter out features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be5a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use glycans within 10 nm of the RBD\n",
    "open_df = restrict_RBD_window(open_df,8)\n",
    "closed_df = restrict_RBD_window(closed_df,8)\n",
    "opening_df = restrict_RBD_window(opening_df,8)\n",
    "print(open_df.shape)\n",
    "\n",
    "# Drop _x, _y, _z features\n",
    "#open_df = drop_feats(open_df,'_x')\n",
    "#open_df = drop_feats(open_df,'_y')\n",
    "#open_df = drop_feats(open_df,'_z')\n",
    "#open_df = drop_feats(open_df,'RBD__2__')\n",
    "#open_df.drop(['RBD__2__backbone0','RBD__2__CH_CA0'],axis=1,inplace=True)\n",
    "\n",
    "# Only use columns that exist in all datasets\n",
    "common_cols = list(set.intersection(*map(set,[open_df,closed_df,opening_df]))) #add or remove val datasets as needed\n",
    "# Only use open & closed datasets for training\n",
    "full_df = pd.concat([open_df.loc[:,common_cols],closed_df.loc[:,common_cols]]).drop(['frame'],axis=1)\n",
    "# OR\n",
    "# Use all datasets\n",
    "#full_df = pd.concat([open_df.loc[:,common_cols],closed_df.loc[:,common_cols],opening_df.loc[:,common_cols],mutant_df.loc[:,common_cols]]).drop(['frame'],axis=1)\n",
    "print(full_df.shape)\n",
    "\n",
    "# Remove highly correlated features\n",
    "clf_df = remove_corr_feats(full_df,0.5)\n",
    "print(clf_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda6938-3b4d-48f1-8386-847fce32375f",
   "metadata": {},
   "source": [
    "# Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13671cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test data\n",
    "train_X, test_X, train_labels, test_labels = prep_ML_data(clf_df,0.3,42,full_df.label)\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "num_pipeline = Pipeline([\n",
    "       ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "train_X_prepared = num_pipeline.fit_transform(train_X)\n",
    "test_X_prepared = num_pipeline.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d437c",
   "metadata": {},
   "source": [
    "# Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20e83f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "# Perform 10-fold cross-validation on training data\n",
    "print('Cross Validation Scores:')\n",
    "y_train_pred = cross_val_predict(sgd_clf,train_X_prepared, train_labels, cv=10)\n",
    "t = time.time()\n",
    "print(cross_val_score(sgd_clf, train_X_prepared, train_labels, cv=10, scoring=\"accuracy\"))\n",
    "print('')\n",
    "print(str(time.time()-t) + ' sec elapsed')\n",
    "\n",
    "# Get overall precision and recall for training data\n",
    "confusion_matrix(train_labels, y_train_pred)\n",
    "print('')\n",
    "print(f' Train precison : {precision_score(train_labels, y_train_pred)}, Train recall {recall_score(train_labels, y_train_pred)}')\n",
    "\n",
    "# Get overall precision and recall for testing data\n",
    "sgd_clf.fit(train_X_prepared,train_labels)\n",
    "y_test_pred = sgd_clf.predict(test_X_prepared)\n",
    "print('')\n",
    "print(f' Test precison : {precision_score(test_labels, y_test_pred)}, Test recall {recall_score(test_labels, y_test_pred)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b8b44",
   "metadata": {},
   "source": [
    "### Display feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = train_X.columns.to_list()\n",
    "#x_vals = train_X.columns.to_list()\n",
    "y_vals = np.abs(sgd_clf.coef_[0])\n",
    "col_vals = train_X.columns.to_list()\n",
    "\n",
    "fig1 = px.bar(x=x_vals,y=y_vals,color=col_vals,labels={'x':'Feature','y':'Importance','color':'Importance'}).update_xaxes(categoryorder='total ascending')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60f883",
   "metadata": {},
   "source": [
    "# Iterative Replicant Analysis\n",
    "\n",
    "Run iterative leave-one-out analysis wherein 1/3 of the replicants are withheld from the training/testing dataset and used as a separate \"validation\" dataset afterwards. The idea is to implement the trained model on a completely \"new\" dataset and see if the model's performance holds up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "RBD_wind = 8\n",
    "leftouts = []\n",
    "train_precs = np.zeros([6,3])\n",
    "train_recalls = np.zeros([6,3])\n",
    "test_precs = np.zeros([6,3])\n",
    "test_recalls = np.zeros([6,3])\n",
    "val_precs = np.zeros([6,3])\n",
    "val_recalls = np.zeros([6,3])\n",
    "top_feats = []\n",
    "for i in range(1,7):\n",
    "    for j in range(1,4):\n",
    "        val_reps_closed = [j]\n",
    "        val_reps_open = [i]\n",
    "        #if i == 6:\n",
    "        #    val_reps_open = [1,6];\n",
    "        #else:\n",
    "        #    val_reps_open = [i,i+1];\n",
    "\n",
    "        # Read open data\n",
    "        fname = '/net/jam-amaro-shared/dse_project/Spike_Dataset/TRAJECTORIES_spike_open_prot_glyc_amarolab/results/FinalExtractedFeature'\n",
    "        dfs_train, dfs_val = read_n_filter_dfs(fname,6,RBD_wind,val_reps_open,val_reps_closed,1)\n",
    "\n",
    "        # Read closed data\n",
    "        fname = '/net/jam-amaro-shared/dse_project/Spike_Dataset/TRAJECTORIES_spike_closed_prot_glyc_amarolab/results/FinalExtractedFeature'\n",
    "        dfs_train, dfs_val = read_n_filter_dfs(fname,3,RBD_wind,val_reps_open,val_reps_closed,0,dfs_train,dfs_val)\n",
    "        print('Val Size: ')\n",
    "        print(pd.concat(dfs_val).shape)\n",
    "        \n",
    "        # Only use columns that exist in all datasets\n",
    "        common_cols = list(set.intersection(*map(set,dfs_train+dfs_val)))\n",
    "        full_df = pd.concat(dfs_train).loc[:,common_cols].drop(['frame'],axis = 1)\n",
    "        full_df.shape\n",
    "        \n",
    "        # Remove highly correlated columns\n",
    "        clf_df = remove_corr_feats(full_df,0.5)\n",
    "\n",
    "        # Split train/test data\n",
    "        train_X, test_X, train_labels, test_labels = prep_ML_data(clf_df,0.3,42,full_df.label)\n",
    "\n",
    "\n",
    "        # Normalize data\n",
    "        num_pipeline = Pipeline([\n",
    "               ('std_scaler', StandardScaler()),\n",
    "            ])\n",
    "        train_X_prepared = num_pipeline.fit_transform(train_X)\n",
    "        test_X_prepared = num_pipeline.transform(test_X)\n",
    "        \n",
    "        # Initialize classifier\n",
    "        sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "        # Perform 10-fold cross-validation on training data\n",
    "        y_train_pred = cross_val_predict(sgd_clf,train_X_prepared, train_labels, cv=10)\n",
    "        t = time.time()\n",
    "        print(cross_val_score(sgd_clf, train_X_prepared, train_labels, cv=10, scoring=\"accuracy\"))\n",
    "        print(str(time.time()-t) + ' sec elapsed')\n",
    "\n",
    "        # Get overall precision and recall for training data\n",
    "        confusion_matrix(train_labels, y_train_pred)\n",
    "        print(f' Train precison : {precision_score(train_labels, y_train_pred)}, train recall {recall_score(train_labels, y_train_pred)}')\n",
    "\n",
    "        # Get overall precision and recall for testing data\n",
    "        sgd_clf.fit(train_X_prepared,train_labels)\n",
    "        y_test_pred = sgd_clf.predict(test_X_prepared)\n",
    "        print(f' Test precison : {precision_score(test_labels, y_test_pred)}, Test recall {recall_score(test_labels, y_test_pred)}')\n",
    "\n",
    "        # Prep data\n",
    "        val_X = pd.concat(dfs_val).loc[:,train_X.keys()]\n",
    "        val_labels = pd.concat(dfs_val).label\n",
    "        val_X_prepared = num_pipeline.transform(val_X)\n",
    "\n",
    "        # Get testing results on unseen replicant(s)\n",
    "        y_val_pred = sgd_clf.predict(val_X_prepared)\n",
    "        print(f' Val precison : {precision_score(val_labels, y_val_pred)}, Val recall {recall_score(val_labels, y_val_pred)}')\n",
    "        \n",
    "        # Save results\n",
    "        leftouts.append(['open '+ str(x) +' ' for x in val_reps_open] + ['closed ' + str(x) + ' ' for x in val_reps_closed])\n",
    "        train_precs[i-1,j-1] = precision_score(train_labels, y_train_pred)\n",
    "        train_recalls[i-1,j-1] = recall_score(train_labels,y_train_pred)\n",
    "        test_precs[i-1,j-1] = precision_score(test_labels, y_test_pred)\n",
    "        test_recalls[i-1,j-1] = recall_score(test_labels, y_test_pred)\n",
    "        val_precs[i-1,j-1] = precision_score(val_labels, y_val_pred)\n",
    "        val_recalls[i-1,j-1] = recall_score(val_labels, y_val_pred)\n",
    "        a = list(np.abs(sgd_clf.coef_[0]))\n",
    "        idx = sorted(range(len(a)), key = lambda k: a[k])[-5:]\n",
    "        x_vals = train_X.columns.to_list()\n",
    "        top_feats.append(list(np.array(x_vals)[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3782a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(top_feats,title='Commonly-Important Features').update_xaxes(categoryorder='total ascending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d37e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPrec = px.imshow(test_precs,range_color=[0.5,1],title='Testing Precisions')\n",
    "testPrec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "testRec = px.imshow(test_recalls,range_color=[0.5,1],title='Testing Recalls')\n",
    "testRec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57754651",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseenPrec = px.imshow(val_precs,range_color=[0.5, 1],title='Precision on Unseen Replicants')\n",
    "unseenPrec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19311561",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseenRec = px.imshow(val_recalls, range_color=[0.5,1],title='Recall on Unseen Replicants')\n",
    "unseenRec.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750eaaf-8215-4f7c-a3fc-21fdee87b7ef",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f32d65-f649-4613-bd46-d0bc1696fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "from biopandas.pdb import PandasPdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b4656a-6e44-49af-aa55-36e663469f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glycan_residues_4m_pdb(dcdObj):\n",
    "    '''Extract glycans from dcd object. Glycans=atoms w/ segment_id == G1, G2, etc'''\n",
    "    dcdObj[0].save_pdb('.tmp.pdb')\n",
    "    pdb_df = PandasPdb().read_pdb('.tmp.pdb')\n",
    "       \n",
    "    pdb_atom_df = pdb_df.df['ATOM']\n",
    "    glycan_mask =  pdb_atom_df.segment_id.apply(lambda x : True if re.match('G\\d+', x) else False)\n",
    "    glycan_residues = pdb_atom_df[glycan_mask].residue_name.unique()\n",
    "    if os.path.exists('.tmp.pdb'):\n",
    "        os.remove('.tmp.pdb')\n",
    "    del pdb_df\n",
    "    return glycan_residues    \n",
    "\n",
    "def get_atom_ids_for_feature(dcd_traj=dcd_traj,feature='protein'):\n",
    "    '''Get atom ids for top-level structures using mdtraj'''\n",
    "    try:\n",
    "        result = (i for i in dcd_traj.top.select(feature))\n",
    "    except :\n",
    "        print(f'[ERROR] {feature} not recognized for atom filtering')\n",
    "        result = []\n",
    "    else :\n",
    "        #print(f'[INFO] # of atoms : {len(list(result))} filtered for {feature}')\n",
    "        return list(result)\n",
    "\n",
    "def build_atom_lup_4_common_features(dcd_traj=dcd_traj,flist = ['protein', 'backbone','sidechain']):\n",
    "    '''Pull atoms for all top-level structures from dcd'''\n",
    "    return {f: get_atom_ids_for_feature(dcd_traj,f) for f in flist}\n",
    "\n",
    "def get_xyz_perFrame(traj,atom_ids):\n",
    "    return pd.DataFrame(columns=['x','y','z'], data=traj.xyz[0,atom_ids])\n",
    "\n",
    "def gen_xyz_Table_4_LUP(traj=dcd_traj, LUP = atom_id_LUP, keyNames =['sidechain','RBD_CA', 'CH_CA', 'GLY','backbone'] ):\n",
    "    frame_0_coord_df = pd.DataFrame(columns=['type','typeID','x','y','z'])\n",
    "    i = 0 \n",
    "    for k in LUP.keys():\n",
    "        if k in keyNames:\n",
    "            frame_0_coord_df = (frame_0_coord_df\n",
    "            .append(get_xyz_perFrame(traj,LUP[k]).assign(type = k).assign(typeID = i))\n",
    "                               )\n",
    "            i += 1\n",
    "    return frame_0_coord_df\n",
    "\n",
    "\n",
    "def gly_4m_featname(featname):\n",
    "    return featname.replace(':ROF','').replace('RBD__2__','').replace(':RMSD','').replace('_x','').replace('_y','').replace('_z','').replace('GLY','G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c07dc8-9a74-47d7-a8f2-ba55cdaf6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trajectory\n",
    "\n",
    "dcdClosed = './amarolab_covid19/TRAJECTORIES_spike_closed_prot_glyc_amarolab/spike_closed_prot_glyc_amarolab_1.dcd'\n",
    "psfClosed = './amarolab_covid19/TRAJECTORIES_spike_closed_prot_glyc_amarolab/spike_closed_prot_glyc_amarolab.psf'\n",
    "trajDir = os.path.dirname(dcdClosed)\n",
    "trajClosed = md.load(dcdFile, top = psfClosed)\n",
    "\n",
    "dcdOpen = './amarolab_covid19/TRAJECTORIES_spike_open_prot_glyc_amarolab/spike_open_prot_glyc_amarolab_1.dcd'\n",
    "psfOpen = './amarolab_covid19/TRAJECTORIES_spike_open_prot_glyc_amarolab/spike_open_prot_glyc_amarolab.psf'\n",
    "trajDir = os.path.dirname(dcdOpen)\n",
    "trajOpen = md.load(dcdFile, top = psfOpen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc94327-5197-46d4-85f6-4526871cd495",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_id_LUP = build_atom_lup_4_common_features(trajClosed)\n",
    "atom_id_LUP['GLY'] =[]\n",
    "for gly in extract_glycan_residues_4m_pdb(trajClosed):\n",
    "    for gly_atom in get_atom_ids_for_feature(trajClosed,f\"resn =~ {gly}\"):\n",
    "        atom_id_LUP['GLY'].append(gly_atom)\n",
    "        \n",
    "atom_id_LUP['RBD_CA'] = get_atom_ids_for_feature(trajClosed,\"resid >= 330 and resid <= 530 and name == CA\")\n",
    "atom_id_LUP['CH_CA'] = get_atom_ids_for_feature(trajClosed,\"((resid >= 747 and resid <= 784) or (resid >= 946 and resid <= 967) or (resid >= 986 and resid <= 1034)) and (name == CA)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d0a99-b011-4da6-87c5-13fa0405dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = []\n",
    "for i in train_X.columns.to_list():\n",
    "    feats.append(gly_4m_featname(i))\n",
    "    \n",
    "for j in feats[:5]:\n",
    "    name = 'segname ' + j\n",
    "    atom_id_LUP[j] = trajClosed.top.select(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d317cb-05d7-4f77-a192-439d54209dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyNames =['sidechain','RBD_CA', 'CH_CA', 'GLY','backbone']+feats[:5]\n",
    "Closed_coord_df = gen_xyz_Table_4_LUP(traj=trajClosed, keyNames =keyNames)\n",
    "figClosed = px.scatter_3d(Closed_coord_df, title='Closed Spike', x='x', y='y', z='z',\n",
    "          color='type',width=800,height=800,opacity=0.5, \n",
    "                    size = [1]*len(frame_0_coord_df)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589501ca-ec35-42b0-9418-d5ae016ebbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "figClosed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab70550-3b44-4a5a-bad5-0719a0b3b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "Open_coord_df = gen_xyz_Table_4_LUP(traj=trajOpen, keyNames =keyNames)\n",
    "figOpen = px.scatter_3d(Open_coord_df, title='Open Spike', x='x', y='y', z='z',\n",
    "          color='type',width=800,height=800,opacity=0.5, \n",
    "                    size = [1]*len(frame_0_coord_df)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae34c3-adc3-486d-985b-27e6dbc5659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "figOpen.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4757794-c56c-4494-b29c-eed37650b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(\n",
    "    children=[\n",
    "        html.H1(children=\"Predicting Effects of SARS-CoV-2 Variant Mutations on Spike Protein Dynamics and Mechanism\",),\n",
    "        html.Div(\n",
    "            dcc.Graph(figure=fig1),\n",
    "        ),\n",
    "        html.Div(children=[\n",
    "            dcc.Graph(\n",
    "            figure=figClosed,\n",
    "            style={'display': 'inline-block'}\n",
    "            ),\n",
    "            dcc.Graph(\n",
    "            figure=figOpen,\n",
    "            style={'display': 'inline-block'}\n",
    "            ),\n",
    "        ]),\n",
    "        html.Div(children=[\n",
    "            dcc.Graph(\n",
    "                figure=testPrec,\n",
    "                style={'display': 'inline-block'}\n",
    "            ),\n",
    "            dcc.Graph(\n",
    "                figure=testRec,\n",
    "                style={'display': 'inline-block'}\n",
    "            ),\n",
    "            dcc.Graph(\n",
    "                figure=unseenPrec,\n",
    "                style={'display': 'inline-block'}\n",
    "            ),\n",
    "            dcc.Graph(\n",
    "                figure=unseenRec,\n",
    "                style={'display': 'inline-block'}\n",
    "            ),\n",
    "        ])\n",
    "    ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a46dd-5990-492c-bebf-0eddfb83ab75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
